package oai

import (
	"context"
	"fmt"
	"log/slog"
	"os"
	"strings"

	"app_server/pkg/openaic"

	"github.com/sashabaranov/go-openai"
	"github.com/spf13/viper"
)

// Client å°è£…äº† OpenAI å®¢æˆ·ç«¯çš„è°ƒç”¨é€»è¾‘
type Client struct {
	client *openai.Client
	debug  bool
}

// NewClient åˆ›å»ºä¸€ä¸ªæ–°çš„ OpenAI å®¢æˆ·ç«¯åŒ…è£…å™¨
func NewClient() *Client {
	// æ£€æŸ¥æ˜¯å¦åœ¨ debug æ¨¡å¼
	debug := os.Getenv("DEBUG") == "true" || os.Getenv("OAI_DEBUG") == "true" || viper.GetString("logLevel") == "debug"

	return &Client{
		client: openaic.Get(),
		debug:  debug,
	}
}

// ChatCompletionRequest åŒ…è£…äº†èŠå¤©å®Œæˆè¯·æ±‚çš„å‚æ•°
type ChatCompletionRequest struct {
	Messages []openai.ChatCompletionMessage
	Model    string
	Stream   bool
}

// CreateChatCompletion è°ƒç”¨ OpenAI API å¹¶å¤„ç†æ—¥å¿—
func (c *Client) CreateChatCompletion(ctx context.Context, req ChatCompletionRequest) (content string, err error) {
	// å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
	if req.Model == "" {
		req.Model = openaic.Model.Chat
	}

	// åœ¨ debug æ¨¡å¼ä¸‹æ‰“å°è¯·æ±‚
	if c.debug {
		defer func() {
			c.logRequest(req, content)
		}()
	}

	// æ„å»º OpenAI è¯·æ±‚
	openaiReq := openai.ChatCompletionRequest{
		Model:    req.Model,
		Messages: req.Messages,
		Stream:   req.Stream,
	}

	// è°ƒç”¨ OpenAI API
	resp, err := c.client.CreateChatCompletion(ctx, openaiReq)
	if err != nil {
		slog.Error("OpenAI API è°ƒç”¨å¤±è´¥",
			"error", err,
			"model", req.Model,
		)
		return "", fmt.Errorf("OpenAI API error: %w", err)
	}

	// è·å–å“åº”å†…å®¹
	if len(resp.Choices) == 0 {
		return "", fmt.Errorf("OpenAI API è¿”å›ç©ºå“åº”")
	}

	content = resp.Choices[0].Message.Content

	return content, nil
}

// CreateChatCompletionSimple ç®€åŒ–ç‰ˆæœ¬çš„èŠå¤©å®Œæˆè¯·æ±‚ï¼Œæ¥å—å•ä¸ªç”¨æˆ·æ¶ˆæ¯
func (c *Client) CreateChatCompletionSimple(ctx context.Context, userPrompt string) (string, error) {
	messages := []openai.ChatCompletionMessage{
		{
			Role:    openai.ChatMessageRoleUser,
			Content: userPrompt,
		},
	}

	return c.CreateChatCompletion(ctx, ChatCompletionRequest{
		Messages: messages,
	})
}

// CreateChatCompletionWithSystem å¸¦ç³»ç»Ÿæç¤ºè¯çš„èŠå¤©å®Œæˆè¯·æ±‚
func (c *Client) CreateChatCompletionWithSystem(ctx context.Context, systemPrompt, userPrompt string) (string, error) {
	messages := []openai.ChatCompletionMessage{
		{
			Role:    openai.ChatMessageRoleSystem,
			Content: systemPrompt,
		},
		{
			Role:    openai.ChatMessageRoleUser,
			Content: userPrompt,
		},
	}

	return c.CreateChatCompletion(ctx, ChatCompletionRequest{
		Messages: messages,
	})
}

// logRequest ç¾åŒ–æ‰“å°è¯·æ±‚æ—¥å¿—
func (c *Client) logRequest(req ChatCompletionRequest, respStr string) {
	fmt.Println("\n" + strings.Repeat("=", 30))
	fmt.Println("ğŸ¤– OpenAI API è¯·æ±‚")
	fmt.Printf("ğŸ’¬ æ¶ˆæ¯æ•°é‡: %d\n", len(req.Messages))

	for _, msg := range req.Messages {
		fmt.Printf("\n[%s]:", msg.Role)
		content := msg.Content
		// ç¼©è¿›æ¶ˆæ¯å†…å®¹
		lines := strings.Split(content, "\n")
		for _, line := range lines {
			fmt.Printf("   %s\n", line)
		}
	}

	if respStr != "" {
		fmt.Printf("\n[AI RESPONSE]: %s\n", respStr)
	}

	fmt.Println(strings.Repeat("=", 30))
}

// FormatMessagesForLog æ ¼å¼åŒ–æ¶ˆæ¯åˆ—è¡¨ç”¨äºæ—¥å¿—è®°å½•
func FormatMessagesForLog(messages []openai.ChatCompletionMessage) string {
	var parts []string
	for _, msg := range messages {
		parts = append(parts, fmt.Sprintf("[%s]: %s", msg.Role, msg.Content))
	}
	return strings.Join(parts, "\n")
}

func Get() *Client {
	return NewClient()
}
